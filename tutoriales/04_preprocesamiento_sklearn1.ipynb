{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhEQ0R-1XppT"
      },
      "source": [
        "\n",
        "<a href=\"https://colab.research.google.com/github/Argentan/DMA_LAB2/blob/master/tutoriales/04_preprocesamiento_sklearn1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGBO0fUHXppU"
      },
      "source": [
        "# Scikit Learn\n",
        "\n",
        "Desde hace años, Scikit Learn es el estándar de facto en términos de paquetes de utilidades y algoritmos de aprendizaje automático. Si bien en los últimos tiempos, tanto en gradient boosting como en deep learning, han surgido otros paquetes que son más populares en determinados contextos, esta librería sigue teniendo toda la funcionalidad de soporte para desarrollar y automatizar procesos de entrenamiento y predicción.\n",
        "\n",
        "Iremos viendo este paquete de una manera funcional, a través de las tareas propias de un proceso de desarrollo e implementación de aprendizaje automático.\n",
        "\n",
        "#### *Nota sobre la API de sklearn*: la gran mayoría de algoritmos y utilidades son clases que se instancia llamándola como una función con parámetro de inicialización y luego tiene dos métodos, `fit` para entrenar el algoritmo y `transform` o `predict` para aplicarlo, según el caso y la utilidad. Existen algunas funciones simples también para funcionalidades más sencillas. \n",
        "\n",
        "## 1. Pre-procesado\n",
        "\n",
        "Luego de la lectura de datos que ya vimos con `Pandas`, la primera tarea de manipulación de datos suele ser el preprocesador, que consiste en la transformación de los datos para que sean procesables y/o más compatibles con el algoritmo elegido o incluso que le permitan más poder explicativo.\n",
        "\n",
        "Las transformaciones para lograr que -algunos algoritmos- puedan procesar los datos son la `asignación de nulos` y, en menor medida, la `codificación de variables no intervalares (categóricas y ordinales) `; mientras que el `escalado y normalización` tiene a lograr una mejor compatibilidad con ciertos modelos. Por otro lado, la creación de variables, aunque contiene una gran parte de arte, es una forma muy potente de agregar poder explicativo al modelo.\n",
        "\n",
        "Veremos estas técnicas en el orden lógico de su utilización, aunque algunas, particularmente las que operan sobre columnas independientes como el escalado y la codificación, son intercambiables.\n",
        "\n",
        "Asimismo, existen algunas técnicas como la discretización (bins) o la transformación binaria que ya no se usan a menudo; al igual que técnicas de detección de valores extremos (`outliers`) y reducción de dimensionalidad que no tienen a tener ya los mismos beneficios que en otras épocas con menos capacidad de cálculo y algoritmos menos sofisticados. \n",
        "\n",
        "### A.- Asignación de nulos o perdidos\n",
        "\n",
        "Excepto alguna implementación de `gradient boosting`, todos los algoritmos de aprendizaje automático son incompatibles con la existencia de nulos en el dataset. \n",
        "\n",
        "Con los valores perdidos hay que ser especialmente cuidadoso, porque a veces tienen de por si un sentido, es decir que no son al azar. Si es así, hay que buscar una forma lógica de completarlos. Si no, se pueden completar de alguna formas distintas.\n",
        "# SKLearn\n",
        "\n",
        "Desde hace años, scikit Learn es el estándar de facto en términos de paquetes de utilidades y algoritmos de aprendizaje automático. Si bien en los últimos tiempos, tanto en gradient boosting como en deep learning, han surgido otros paquetes que son más populares en determinados contextos, esta librería sigue teniendo toda la funcionalidad de soporte para desarrollar y automatizar procesos de entrenamiento y predicción.\n",
        "\n",
        "Iremos viendo este paquete de una manera funcional, a través de las tareas propias de un proceso de desarrollo e implementación de aprendizaje automático.\n",
        "\n",
        "#### *Nota sobre la API de sklearn*: la gran mayoria de algoritmos y utilidades son clases que se instancia llamandola como una función con parámetro de inicialización y luego tiene dos métodos, `fit` para entrenar el arlgoritmo y `transform` o `predict` para aplicarlo, según el caso y la utilidad. Existen algunas funciones simples tambien para funcioanlidades mas sencillas. \n",
        "\n",
        "## 1. Pre-procesado\n",
        "\n",
        "Luego de la lectura de datos que ya vimos con `Pandas`, la primera tarea de manipuación de datos suele ser el pre-procesado, que consiste en la transformación de los datos para que sean procesables y/o más compatibles con el algoritmo elegido o incluso que le permitan más poder explicativo.\n",
        "\n",
        "Las transformaciones para lograr que -algunos algoritmos- puedan procesar los datos son la `asignación de nulos` y, en menor medida, la `codificación de variables no intervalares (categóricas y ordinales)`; mientras que el `escalado y normalización` tiene a lograr una mejor compatibilidad con ciertos modelos. Por otro lado, la creación de variables, aunque contiene una gran parte de arte, es una forma muy potente de agregar poder explicativo al modelo.\n",
        "\n",
        "Veremos estas técnicas en el orden lógico de su utilización, aunque algunas, particularmente las que operan sobre columnas independientes como el escalado y la codificación, son intercambiables.\n",
        "\n",
        "Asimsimo, existen algunas tecnicas como la discretización (bins) o la binarización que ya no se usan a menudo; al igual que técnicas de detección de valores extremos (`outliers`) y reducción de dimensionalidad que no tienen a tener ya los mismos beneficios que en otras epocas con menos capacidad de calculo y algoritmos menos sofisticados. \n",
        "\n",
        "### A.- Asignación de nulos o perdidos\n",
        "\n",
        "Excepto alguna implementaciones de `gradient boosting`, todos los algoritmos de aprendizaje automático son incompatibles con la existencia de nulos en el dataset. \n",
        "\n",
        "Con los valores perdidos hay que ser especialmente cuidadoso, porque a veces tienen de por si un sentido, es decir que no son al azar. Si es asi, hay que buscar una forma lógica de completarlos. Si no, se pueden completar de alguan formas distintas.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GrgqZRCsXppV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "X = pd.DataFrame([\n",
        "    [1,2,3,np.nan],\n",
        "    [np.nan, np.nan, np.nan, 0],\n",
        "    [-5, 0, 25, np.nan],\n",
        "    [1,-1, np.nan, np.nan]\n",
        "], columns=[f\"c{i}\" for i in range(4)])\n",
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7y39u5zFsDX"
      },
      "source": [
        "Podemos eliminar filas o columnas completas cuando posean muchos nulos usando `dropna`\n",
        "\n",
        "Con `axis` definimos si se aplica sobre filas o columnas\n",
        "\n",
        "Con `thresh` a partir de cuantos nulos consideramos que debe borrarse (cuidado que inicia en 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFlHYd4CXppc"
      },
      "outputs": [],
      "source": [
        "X.dropna(axis=0, thresh=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkAkh6J7GL3g"
      },
      "source": [
        "Con `axis = 1` eliminamos por columna en lugar de fila"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "341DvG3yXppg"
      },
      "outputs": [],
      "source": [
        "X.dropna(axis=1, thresh=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozslVvGUGWlV"
      },
      "source": [
        "Con `fillna` podemos completar con algun valor constante\n",
        "\n",
        "Es recomendable utilizar algún valor fuera del rango de valores de la variable para que se identifique claramente que era perdido"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWIi6HiVXppj"
      },
      "outputs": [],
      "source": [
        "X.fillna(999)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipWIW-n-GmZe"
      },
      "source": [
        "Con `SimpleImputer` podemos remplazarlo usando una función de agregación, como por ejemplo:\n",
        "\n",
        "\n",
        "*   mean: La Media\n",
        "*   median: La Mediana\n",
        "*   most_frequent: Valor más frecuente\n",
        "*   constant: un valor constante\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2Z_fgeYNXppo"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "#media\n",
        "SimpleImputer(missing_values=np.nan, strategy='mean').fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Niy9DuNGXppt"
      },
      "outputs": [],
      "source": [
        "#media\n",
        "SimpleImputer(missing_values=np.nan, strategy='most_frequent').fit_transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDlSXbz7HETP"
      },
      "source": [
        "Con `IterativeImputer` podemos entrenar un modelo para realizar la imputación\n",
        "\n",
        "Por default, utiliza un modelo de regresión de tipo Bayesian Ridge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDdgWiiIXppw"
      },
      "outputs": [],
      "source": [
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "\n",
        "#con un modelo\n",
        "IterativeImputer(max_iter=10, random_state=0).fit_transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsiPFMbEHsJi"
      },
      "source": [
        "También podemos crear una Matriz de nulos utilizando `MissingIndicator`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9nm9OWXXpp0"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import MissingIndicator\n",
        "\n",
        "MissingIndicator(missing_values=999).fit_transform(X.fillna(999))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2P-t8wjXpp4"
      },
      "source": [
        "### B.- Codificación de variables ordinales y categorías\n",
        "\n",
        "Los algoritmos no pueden procesar datos que formato texto o `string`, hay que transformarlos a números. Existen algunas opciones para codificar estas variables, dependiendo de su naturaleza. \n",
        "\n",
        "Si son ordinales, fácilmente se pueden traducir a número, en una escala arbitraria y solo manteniendo los ordenes y valores equidistantes. \n",
        "\n",
        "Si son categóricas, no es posible hacer lo mismo. Algunas implementaciones de gradient boosting toleran variables categorías, pero en general los demás no. Así que hay que omitirlas o transformarlas.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pz6GKfSdXpp4"
      },
      "outputs": [],
      "source": [
        "X = pd.DataFrame([\n",
        "    ['M', 'CABA', 'medio'],\n",
        "    ['M', 'CABA', 'alto'],\n",
        "    ['F', 'PBA', 'alto'],\n",
        "    ['F', 'Córdoba', 'bajo'],\n",
        "    ['F', 'Córdoba', \"medio\"]\n",
        "], columns=[\"sexo\", \"provincia\", \"ingreso\"])\n",
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwhj3Sy6IAU8"
      },
      "source": [
        "Con `OrdinalEncoder` podemos crear variables codificadas de forma ordinal en orden alfabético"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3wDLuWHXpp8"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
        "\n",
        "OrdinalEncoder().fit_transform(X[[\"sexo\", \"ingreso\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHO1SEmoXpp_"
      },
      "outputs": [],
      "source": [
        "OrdinalEncoder().fit_transform(X[[\"sexo\", \"ingreso\"]].sort_values(\"sexo\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dzK3wDcIpop"
      },
      "source": [
        "También puedo indicarle el orden que deseo que codifique, si existe una lógica de magnitud para esa variable que no sea el orden alfabético"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbUuwNjhXpqC"
      },
      "outputs": [],
      "source": [
        "encoder = OrdinalEncoder(categories=[[\"F\", \"M\"], [\"bajo\", \"medio\", \"alto\"]])\n",
        "encoder.fit_transform(X[[\"sexo\", \"ingreso\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrzt75tdXpqF"
      },
      "outputs": [],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pv5fHUoWXpqI"
      },
      "outputs": [],
      "source": [
        "encoder.categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZyb8TDCXpqR"
      },
      "outputs": [],
      "source": [
        "pd.factorize(X.sexo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tG7xBJJ5Jeqm"
      },
      "source": [
        "También puedo usar `OneHotEncoder` para realiza una codificación dummy o de tipo one-hot, es decir, donde cada valor de la variable se convierte en una columna con un binario que es 1 en caso de que tome ese valor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIFwAqdhJ-TB"
      },
      "source": [
        "![onehot.JPG](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAeAB4AAD/4RDyRXhpZgAATU0AKgAAAAgABAE7AAIAAAANAAAISodpAAQAAAABAAAIWJydAAEAAAAaAAAQ0OocAAcAAAgMAAAAPgAAAAAc6gAAAAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFBhYmxvIEFsYmFuaQAAAAWQAwACAAAAFAAAEKaQBAACAAAAFAAAELqSkQACAAAAAzczAACSkgACAAAAAzczAADqHAAHAAAIDAAACJoAAAAAHOoAAAAIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAyMDIwOjEwOjE1IDEzOjQ2OjQ5ADIwMjA6MTA6MTUgMTM6NDY6NDkAAABQAGEAYgBsAG8AIABBAGwAYgBhAG4AaQAAAP/hCx9odHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvADw/eHBhY2tldCBiZWdpbj0n77u/JyBpZD0nVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkJz8+DQo8eDp4bXBtZXRhIHhtbG5zOng9ImFkb2JlOm5zOm1ldGEvIj48cmRmOlJERiB4bWxuczpyZGY9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkvMDIvMjItcmRmLXN5bnRheC1ucyMiPjxyZGY6RGVzY3JpcHRpb24gcmRmOmFib3V0PSJ1dWlkOmZhZjViZGQ1LWJhM2QtMTFkYS1hZDMxLWQzM2Q3NTE4MmYxYiIgeG1sbnM6ZGM9Imh0dHA6Ly9wdXJsLm9yZy9kYy9lbGVtZW50cy8xLjEvIi8+PHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9InV1aWQ6ZmFmNWJkZDUtYmEzZC0xMWRhLWFkMzEtZDMzZDc1MTgyZjFiIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iPjx4bXA6Q3JlYXRlRGF0ZT4yMDIwLTEwLTE1VDEzOjQ2OjQ5LjczMzwveG1wOkNyZWF0ZURhdGU+PC9yZGY6RGVzY3JpcHRpb24+PHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9InV1aWQ6ZmFmNWJkZDUtYmEzZC0xMWRhLWFkMzEtZDMzZDc1MTgyZjFiIiB4bWxuczpkYz0iaHR0cDovL3B1cmwub3JnL2RjL2VsZW1lbnRzLzEuMS8iPjxkYzpjcmVhdG9yPjxyZGY6U2VxIHhtbG5zOnJkZj0iaHR0cDovL3d3dy53My5vcmcvMTk5OS8wMi8yMi1yZGYtc3ludGF4LW5zIyI+PHJkZjpsaT5QYWJsbyBBbGJhbmk8L3JkZjpsaT48L3JkZjpTZXE+DQoJCQk8L2RjOmNyZWF0b3I+PC9yZGY6RGVzY3JpcHRpb24+PC9yZGY6UkRGPjwveDp4bXBtZXRhPg0KICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICA8P3hwYWNrZXQgZW5kPSd3Jz8+/9sAQwAHBQUGBQQHBgUGCAcHCAoRCwoJCQoVDxAMERgVGhkYFRgXGx4nIRsdJR0XGCIuIiUoKSssKxogLzMvKjInKisq/9sAQwEHCAgKCQoUCwsUKhwYHCoqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioq/8AAEQgA8AIqAwEiAAIRAQMRAf/EAB8AAAEFAQEBAQEBAAAAAAAAAAABAgMEBQYHCAkKC//EALUQAAIBAwMCBAMFBQQEAAABfQECAwAEEQUSITFBBhNRYQcicRQygZGhCCNCscEVUtHwJDNicoIJChYXGBkaJSYnKCkqNDU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6g4SFhoeIiYqSk5SVlpeYmZqio6Slpqeoqaqys7S1tre4ubrCw8TFxsfIycrS09TV1tfY2drh4uPk5ebn6Onq8fLz9PX29/j5+v/EAB8BAAMBAQEBAQEBAQEAAAAAAAABAgMEBQYHCAkKC//EALURAAIBAgQEAwQHBQQEAAECdwABAgMRBAUhMQYSQVEHYXETIjKBCBRCkaGxwQkjM1LwFWJy0QoWJDThJfEXGBkaJicoKSo1Njc4OTpDREVGR0hJSlNUVVZXWFlaY2RlZmdoaWpzdHV2d3h5eoKDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uLj5OXm5+jp6vLz9PX29/j5+v/aAAwDAQACEQMRAD8A+kaKKKACisHxnrNzoXhyS9stvmq6gbhkc15r/wALU1/0t/8Av3QdtDA1cRDnhax7RRXi/wDwtTX/AEt/+/dH/C1Nf9Lf/v3TsdH9lYjy+89oorxf/hamv+lv/wB+6P8Ahamv+lv/AN+6LB/ZWI8vvPaKK8X/AOFqa/6W/wD37o/4Wpr/AKW//fuiwf2ViPL7z2iivF/+Fqa/6W//AH7o/wCFqa/6W/8A37osH9lYjy+89oorxf8A4Wpr/pb/APfuj/hamv8Apb/9+6LB/ZWI8vvPaKK47wB4ovvEsF4+oeXmFlC7Fx1rsaR59alKjNwlugooooMgooooAKKKKACiiigAoorxC6+LXiGG8mjQW+1HKj936Guijh5178nQyqVo0rcx7fRXhf8Awt7xH6W3/fuj/hb3iP0tv+/ddH9n1/Ix+uUj3SivC/8Ahb3iP0tv+/dH/C3vEfpbf9+6P7Pr+QfXKR7pRXhf/C3vEfpbf9+6P+FveI/S2/790f2fX8g+uUj3SivC/wDhb3iP0tv+/dH/AAt7xH6W3/fuj+z6/kH1yke6UV4X/wALe8R+lt/37rR1b4oa7ZR2BhFvm4tllfKdyxH9KTwFZO2g/rVO1z2OivC/+FveI/S2/wC/dH/C3vEfpbf9+6f9n1/IX1yke6UV4X/wt7xH6W3/AH7o/wCFveI/S2/790f2fX8g+uUj3SivC/8Ahb3iP0tv+/dH/C3vEfpbf9+6P7Pr+QfXKR7pRXhf/C3vEfpbf9+6P+FveI/S2/790f2fX8g+uUj3SivC/wDhb3iP0tv+/daMPxQ12Tw7dXrC382KdI1+TjBBz/Kk8BWXYaxVNnsdFeF/8Le8R+lt/wB+6P8Ahb3iP0tv+/dP+z6/kL65SPdKK8L/AOFveI/S2/790f8AC3vEfpbf9+6P7Pr+QfXKR7pRXhf/AAt7xH6W3/fuj/hb3iP0tv8Av3R/Z9fyD65SPdKK8L/4W94j9Lb/AL90f8Le8R+lt/37o/s+v5B9cpHulFeF/wDC3vEfpbf9+60dB+KGu6jrMVrcC38twxOE54Un+lJ4Csld2GsXTbsex0V4X/wt7xF6W3/fuj/hb3iP0tv+/dP+z6/kL63SPdKK8L/4W94j9Lb/AL90f8Le8R+lt/37o/s+v5B9cpHulFeF/wDC3vEfpbf9+6P+FveI/S2/790f2fX8g+uUj3SivC/+FveI/S2/790f8Le8R+lt/wB+6P7Pr+QfXKR7pRXhf/C3vEfpbf8AfugfF7xFnpbf9+6P7PreQfW6R7pRVXTLh7vSrW4lxvliV2x6kVargas7HWtQooopAFFFFAHI/E3/AJEqb/roleLWVv8AbNQt7bdt86VU3YzjJxmvafib/wAiVN/10SvHdF/5D1h/18x/+hCmj6fK3bDNruzup/hdYW9wlvN4iijuJBmOKSMBm+g3c1xniHQLnw5qzWN2Vc4DI69HU969T8Xy+GLTX7O7195/tcMQaKNASpAYkZwPXPeotJutP8XXl/r0tvEfsiiK3W6GVQcncwoMqOMrRiqk7uNu1teljx2tO78O6jZaNBqlxCq2lwQI3Dgk59utd94gOj3Ph6S5uJ9JbUbdw8LWg2h8H7pHer2v+IpYfh1Y3y2Vs7XShGjKZVMqeQO1M6XjZvl5Y7uzv+h4/RSnk0lB6gUUUUAFFFFAHqnwf/49dR/30/ka9KrzX4P/APHrqP8Avp/I16VSZ8fmP+9S/roFFFFI4AooooAKKKKACiiigANfK9//AMhG4/66t/Ovqg18r3//ACEbj/rq3869jLN5fI8/G7ROi8JeAdQ8UxtcrIlpZIdpnkGcn0A71raz8MYtP0me+sdftbkW4y6thfwyCea6IR3F78D4Y9Cy0qpiVYvvHDfMK8pXTtQMTstrP5YIDnYcA9s11QnUqyb5rJO1jCUYQily3utynitPQ/D+oeI717TSollmRDIQzheAQOp+or1vQbZtOtdMstTsdDs/PUBoXG6WbPccdfzqbw0sOjfEfV9CsrWGO2aP7UrBfmUkJ8oP93npUzxjtLlWqHHDK6uzw+4gktrmSCYYkicowznBBwajroPGmsSax4jnaW1htzbu8IEKbdwDHk+9c/XfBtxTZyySTaQUUUVRIVteIf8AU6T/ANeK/wDoTVi1teIf9TpP/Xiv/oTVEviRS+Fl/wAE+Dl8XXF1G96bQW6Bs+Xuzn8RXQN8J4LuKQaJ4jtL2dOseB+RKscflUnwb/4+tW/64D+tYPgyx1KT4gW8llFKqpcEyuAQAmTnNcVSdT2k7SsonTGMOSN43uczqGn3Ol6hNZX0Rinhba6nsarV7jcaPpWu/Fa8luo0uPsFlGXhPIeTJ6jvgY/Sqej3un+OG1LTNQ8Ow2aW6MY5UQBkwcdcDBprGe7dx6K/zB4fW1/Q8aor1jRLSw8J+AZtbXTotSu2mZMyKDgbsfgOKs6zcWmrfCO51OPSYbCWQjKpGBzvHIOO9V9a96yjpe1yfYaavW1zx6iiiu05gratf+RLvv8Ar7i/9BasWtq1/wCRLvv+vuL/ANBaonsvVFw3E8MaNaa5qzWuoalFpsQiLiaXGCQRxyR6/pXbyfCbTIbNLuXxRCls/wB2ZkUI30bdivL69V8S/wDJD9H/AO2X9a5cQ6inHlla7sbUVBxfMr2POdb0+DS9YntLS7S8hjbCzpjD8exNUMV6j4xsoR4H8MSQWyBmaPeyIMn5e5rW8R2VtH438KRrbQqrj51EYAbg9R3pRxWiuu/4DdDV69vxPHba2lu7qK3gXdJK4RATjJJwK3G8J3mneKrDSNbj8lrp0z5bhjtZsZyMjsa9E1zxZb6L47i0ax0Sx+eaJZJ2jG7LY5GPQGpfG+sSL450bSfssJjeWGXzynzg7zxn04qPrNSTVo2TVyvYwSet2med+O/Dlp4Y8QCxsXleMwq+ZSCcnPoB6VzNe16todprnxejj1BRJDDZrIY26OQTgGprtdDu476w1mbQ47ZVKxC3XbJCe2TShi+WMU1d21CWHvJtOyPDq2vCX/IzW/8Auyf+gNWRMqpO6o25VYgMO4rX8Jf8jNb/AO7J/wCgNXdU+B+hyw+JGLXo9p8L7B9DtNRv/EMdklwgYebGqgE9slhmvOK9v1KTQI/h3ox8TxyyW2xNgizndj2rmxVScOVQe76G9CEZczl0OLh8G+HIfE0djeeJYZbRrcyefE6KN2cbc5I6c1xl9DDBqE8VpL58KSMscmMb1B4NeleCY/D158Q5BoVsxsvsZ+S4Xd82RnrUvhCTRILnXUlFlHqpvJFge8TMYXPAH456VCryg3e70RfslJK1lqzhvBuiW/iHxRb6dePIkUoYkxkBuAT3qr4j02LSPEV7YWxdooJNqlzkkY716Xa2moW3xb0w6jY2VrvhfY1muEk+U5P1rYsL3TNd8Va1oM2jW4SIFnmZQWkY9T04qZYqSnzWurX/ABGqCceXrc8IoqzqEK22pXEMf3Y5WUfQGq1ekndXOLYKUdRSUo6igD6g0L/kX7D/AK4J/Kr9UNC/5F+w/wCuCfyq/XyE/iZ9DHZBRRRUjCiiigDkfib/AMiVN/10SvFbS4a0vIbhAGaGRXAPcg5r6C8SaNDrujPY3E5gRmDFx2xXFf8ACqtL/wCgvJ+S00e7l+Lo0aLhUfU4bxN4ln8T30V1cwpC0UflgIc5GSf603w/4lvvDlw8lkVZJBiSJxlWru/+FVaX/wBBeT8lo/4VVpf/AEF5PyWjQ7PrmD5PZ9O1mchrvjO51uxFn9jtbWHduIijGSfrUln46vrbw6dHltoLiHYURpBygIx+ma6v/hVWl/8AQXk/JaP+FVaX/wBBeT8lo0J+s4HlUem+zPLaSvU/+FVaX/0F5PyWj/hVWl/9BeT8lp3N/wC0sN3/AAZ5ZRXqf/CqtL/6C8n5LR/wqrS/+gvJ+S0XD+0sN3/BnllFep/8Kq0v/oLyfktH/CqtL/6C8n5LRcP7Sw3f8GL8H/8Aj11H/fT+Rr0quc8I+F7bw1FcJaXbXImIJJxxj6V0dSfOYypGrXlOOzCiiig5AooooAKKKKACiiigANfK9/8A8hG4/wCurfzr6ory+f4SaVNcSSNrMgLsWIwvGTXo4GvCi5c/U48VSlUS5Tz7w14y1Xwu7CwkVoXOWhkGVJ9fatrVfitrGo2L20Vvb2qyDDMi7ifzro/+FQaT/wBBqT8lo/4VBpP/AEGpPyWu2VfCSlzNa+hzKliEuVbHOw/FPUkjtzcafZXFxbgKtw6fNj+lZ/8Awn+pL4wfxDDFFHPJGI3i6qygAY/QV2X/AAqDSf8AoNSfktH/AAqDSf8AoNSfktJVsGr2X4Mbp4hnnXiXxBJ4k1QXstrDbME2FYhweScn35rIr1z/AIVBpP8A0GpPyWj/AIVBpP8A0GpPyWtY4zDxVkzN4atJ3Z5HRXrn/CoNJ/6DUn5LR/wqDSf+g1J+S1X16h3/AAF9Vq9jyOtrxD/qdJ/68V/9CavQv+FQaT/0GpPyWruofC7TL1LQSatIn2eARLgL8wBJz+tQ8bRck7lLDVLPQ838J+L7nwlPcS2lvHOZ1CkSEjGK3br4t6xLbNHZWlrZs3V41ya3v+FQaT/0GpPyWj/hUGk/9BqT8lrOVbCTlzSWvoy40sRFWR5xpXiTU9I1o6pa3BNyxPmM/PmZ6g10Wp/FPV7+wktoLe3szMMSSxD5mrpf+FQaT/0GpPyWj/hUGk/9BqT8lqpYjCSfNLf0EqOIirIp+AR4lj8MyPpQs762kkI+yXDcj1Na3jrUp7L4dGy1hrdNQunAEEHRFBz+gFMtvhbZ2ZJtfEVzDnrsYCmz/CmwupN9zr9xK3q5BNczqUJVedvrfY2UKqhypfiePUV65/wqDSf+g1J+S0f8Kg0n/oNSfktd316h3/A5fqtXseR1tWv/ACJd9/19xf8AoLV6F/wqDSf+g1J+S1di+F2mR6NPZDVpCksqyF8LwQCMfrUSxtFrRlRw1RPY8Wro7/xldah4RtdAkt41gttu2QE7jiu5/wCFQaT/ANBqT8lo/wCFQaT/ANBqT8lpyxeHk030BYesr26nKaZ8SdT07RYtOe2trpIP9U8y5KelM1L4h32p63p2pzWsKy2GdqqTh/rXXf8ACoNJ/wCg1J+S0f8ACoNJ/wCg1J+S1l7bB3vb8GX7PEWsec654hudb8Qtq7osE5KsAh4UqBg/pW9qPxKv9UWzN1Y2pmtZUlEoHzMVOcewrqP+FQaT/wBBqT8lo/4VBpP/AEGpPyWqeIwrtfptuJUa6v5nE6j451K+8Txa5CEtbmJAgCHIIHr+daGofE2/v7GaAadYxSTrtkmEYLMK6b/hUGk/9BqT8lo/4VBpP/Qak/JaXt8Jppt5MfssRr5nkfWtrwl/yM1v/uyf+gNXoX/CoNJ/6DUn5LV3Svhdpmm6lHdRatJIyBgFIXnII/rVzxtFxaTIjhqiknY8Wro9Y8ZXWseHbPSJreNIrXG11JycDFd1/wAKg0n/AKDUn5LSf8Kg0n/oNSfktOWLw8mm+gLD1kml1PPfC/iWfwtqrX1rCkztGY9rnAwSP8K0tK8fXWmLdI2nWVzFcTtOVljyQxOetdh/wqDSf+g1J+S0f8Kg0n/oNSfktRLEYWTbl+o40a8dEchJ8Q9Um8U2+tzxRM9sjJFAOFUEYNM03x5eaZ4lvtZitYnlvBhkJOF+ldl/wqDSf+g1J+S0f8Kg0n/oNSfktL2+Etb5bMfssRe55RdXBuruWdgA0rlyB2yair1z/hUGk/8AQak/JaP+FQaT/wBBqT8lrb69QXX8DP6rV7HkdKOor1v/AIVBpP8A0GpPyWl/4VBpP/Qak/JaPr1Dv+AfVavY9E0L/kX7D/rgn8qv1BY262lhBbo29Yowgb1wKnr52Tu2z2FsFFFFSMKKKKAKWrf8eDfUVgVv6t/x4N9RXIa/qX9j+HdQ1IJvNpbSTBfUqpOKR00vhJb7VtP0xQ2pX9taK3QzzKgP5mpre6gu4FmtJo54m+68bhlP4iuR8I+EdPk0e31fXbeLVNX1CJZ7i6ukEhBYZ2JnhVGcACtqz0LSvDX2290mwMJmG+WC2Bw5H91BwD9BQXqbNFcxb+MH/tK2tdV0W90xbxtlvLOUKs2M7TtYlT9ay9M8U69cfEDUtNm0a5NpEsO1fMixCDnLnnJB645NAXR3dFFFBQUUUUAFFFFAGvon3JfqK1aytE+5L9RWrTOSp8TCiiiggKKKKACiiigAooooAK5CT/Wt9TXX1yEn+tb6mtaZMiC4uYLSBp7qaOCJBlpJGCqPqTUiOsiK6MGVhkMDkEVxHxO0GPUvDN7fXdzM0Nnau0doDiMydnPqR2B4rqtF/wCQDYf9e0f/AKCK06kl6iiimIKKKKACiiigAqe5+7D/ANcx/M1BU9z92H/rmP5mgZVlljgiaSZ1jjUZZnOAB7mobLUbLUYTLp93BdRg4LwSBwD9RXK+MYxq3inw/odz81lO8lxcRH7soQcKfUZOcVFfWNr4d+I+hTaTbx2keqRzW1zFCoRH2KGRio4yORn3pXA7iiiimIKKKKACiiigAqdP+PGT/fFQVOn/AB4yf74oYyCqkeradNfNZQ39s90n3oFmUuv1XOayfH2pz6P4B1e9s3KXEduRG46qzfKD+Gc1z3iPwjpmifDsz6baxQX+lxLcxXaKBKZF5LF+p3c5z1zSbA9CoqvYXH2vTba5IwZolkx9QDVimIKKKKACiiigAqez/wCPpfof5VBU9n/x9L9D/Kh7DIKqXeq6fYSRx319bWzyHCLNMqFj7AnmrZOBXA+EtG0/xLHrGq63Zw3s11eSwAzoH8uNDtCrnp+FAHegggEHIPQilrk/h3NINAuLCV2kGnXktqjMcnYrfLz9K6ygAooooEFFFFABRRRQB1tv/wAe0f8AuipKjt/+PaP/AHRUlcpqFFFFABRRRQBS1b/jwb6iuZvbSLULCezuV3Q3EbRuPVSMH+ddPqoJsGxzyKwNrf3T+VI6aXwnCaPea94PsI9H1PSbnVLa1Hl2t7ZgOXjH3Q69QwHFTX974s1fQdTksdPOmkxgWiO489jn5j6DjpXa7W/un8qNrf3T+VBdjyg6RcXWraHLYaNrA+z3iPdT38zHAweik4PPcCumRb3SviTe3LafcT2mpQQxpPCu5Y2XIO70612O1v7p/Kja390/lQFhKKXa390/lRtb+6fyoKEopdrf3T+VG1v7p/KgBKKXa390/lRtb+6fyoA1tE+5L9RWrWXooISXIxyK1KZyVPiYUUUUEBRRRQAUUUUAFFFFABXISf61vqa6+uSkRvMb5T1PataZMjn/ABpaT3/gvVLW0iaWeW3ZURerH0rR0mN4dGsopVKukCKynsQozVzY390/lRsb+6fyrUkSil2N/dP5UbG/un8qAEopdjf3T+VGxv7p/KgBKKXY390/lRsb+6fyoASp7n7sP/XMfzNQ7G/un8qnuFbbD8p/1Y7e5pAcf4u02+a90vW9Kg+03GmysXgBwZI2GGA9+9VLWPUPE3jKx1S606fT7DS45PKW5GHllcAE47AAfrXabG/un8qNjf3T+VFgEopdjf3T+VGxv7p/KmAlFLsb+6fyo2N/dP5UAJRS7G/un8qNjf3T+VACVOn/AB4yf74qHY390/lU6q32GT5T98dqTAw/E2jjxB4Y1DSmbZ9rgaNW/utjg/niuQv7nxD4g8Np4bl0W4tbuZVgvLt8eSqDhmU98gcD3r0TY390/lRsb+6fyosBFbwrbWsUEf3I0CL9AMVJS7G/un8qNjf3T+VMBKKXY390/lRsb+6fyoASil2N/dP5UbG/un8qAEqez/4+l+h/lUOxv7p/Kp7NW+1L8p6Ht7UnsBXrhLN9V8G3WpWUOj3Oo2tzcNcWklsAQC/JVvTnvXebG/un8qNjf3T+VMDnvBmjXOjaCV1DH2y6me5nCngM5zj8OldBS7G/un8qNjf3T+VACUUuxv7p/KjY390/lQAlFLsb+6fyo2N/dP5UAJRS7G/un8qXY390/lQB1dv/AMe0f+6KkqO3/wCPaP8A3RUlcpoFFFFABRRRQBFckiE49ao729au3X+oP1rLupGis5pE+8kbMPqBSNI7E+9vWje3rXm/hdvHXiLwnYa3F4nsY5LyHzRbyaWCo68Fg4P41veFvFF5qOo3mh+IbSOy1mxUO6xMWinjPAkQnnGex6UFaHVb29aN7etRGeJZNjSoG/ulhmnkgDJOBQA7e3rRvb1qFbiFgSsyEA4OGFS0ALvb1o3t60lFAxd7etG9vWkooAt2ZJDZqzVWy6NVqmYy3CiiigQUUUUAFFFFABRRRQAVlmRtx571qVkn7x+tVETF8xvWjzG9a4q91fX9c8WX2i+Gbq206HS0Q3V3PB5zPI4yqKuQAMck+9aHg/X7zVo7+y1iOKPU9Mn8i48nIR+Mq4B5AI7VQjpfMb1o8xvWm0UAO8xvWjzG9abRQA7zG9aPMb1ptFADvMb1p7u2F5/hqKnydE/3aAE8xvWjzG9ay9e1G60vSXn0/T5dQuSQkUEXdj0JPZR3NYvw91zV9c0e9fxAYDeW99LbkQLhQFOMD1+tAHXeY3rR5jetNooAd5jetHmN602igB3mN60eY3rTaKAHeY3rTw7eS3PcVFTx/qW/3hQAnmN60eY3rWbr+sQeH/D19q12C0NnA0zKOrYGcD69K4u41vxpouhQeJ9XmsJrNtkl1pkVuVa3iYjlZN3zMoPORjg0AejeY3rR5jetRxyLLEkkZ3I6hlI7g06gB3mN60eY3rTaKAHeY3rR5jetNooAd5jetPidjIMmoqfD/rBQAnmN60eY3rTa4WPV/FHijUNSk8NXllp9hp8zW8f2i2MzXUi/eydw2rnjjmgDvPMb1o8xvWsHwh4gfxJ4fjvLiEQXSO0NxEpyEkU4YD2yK3KAHeY3rR5jetNooAd5jetHmN602igB3mN60eY3rTaKANWP/Vr9KdTY/wDVr9KdWZQUUUUAFFFFAEN1/qD9ayb/AP5B1z/1yb+RrWuv9QfrWe6LJGyOMqwII9RSNI7HIfC6aKL4U6C0kioFtFyWbGOTWJJfyax4/wBW1vQB58GlaS9sJ1GVlnJ3bQe+MVuxfC/wrCixpYyeUvSL7Q+z6YziumstPtNNs0tLC3jt7dBhY41wBQUee+HvDPhvVvAkOq6tKLi9ngMtxqEk5EsUnU4Oflwe3tWZ/aupaj4J8J2+sXc0Vnf35gu7oMUaSJQ3lgsOm/Aya7q48AeG7m7e4l05cyNveNXYI59SoODUnioW9r4eWCTQ21Sx3KkttCoJjT+8F7446UCscV8QfDfh7Q9L0ufSdun3DapaIIoJCBcgzKSGXPOOufavVK8jl0jSNfutPsfC2i3sbC9hnury8jcC3ijcOVUv3O0DAr1ygaFooooGFFFFAFqy6NVqqtl0arVMyluFFFFBIUUUUAFFFFABRRTJJo4tvmOF3HAyetAD6yT94/WtbqOKyT94/WqiJnDeFZE0/wCIPi6yumWOa4nhu4txxvjMYXI9cFSKd4KcXvjDxXqVv81rJcxxRuOjsi4Yj8eK39a8K6P4gkjk1S0EksQISRWKMAeoyOce1XdO02z0ixjs9OgS3t4x8qIOKoRaooopgFFFFABRRRQAU+Ton+7TKfJ0T/dpAMrivhr/AMeeuf8AYYuf/Q67WqenaVZ6Uk62EIiE8zTSAH7zsck0AXKKKKYBRRRQAUUUUAFPH+pb/eFMp4/1Lf7wpAcl8TrKbUPhlrtvaoXlNqXVF6ttIYj8hVDxprdje/CW5ntZUlXUbRY7ZUOS7OAFAHrk13JAYEEZB6g1z1r4E8O2WprfW+mosyOXQbiURj3Vc4BoA1tKge10azgl+/FAiN9QoBq3RRTAKKKKACiiigAp8P8ArBTKfD/rBSAYRkEVw3w5uYdP03WdPu5Eins9SneVXOCFY7g30xXc1hat4M0LXLz7VqNirzEbWdWK7x6Ng8j60AZHwxBl0TUb5VIhvdSnnhz3QtwfxrtKjtraG0to7e1jWKGNQqIowFHpUlABRRRTAKKKKACiiigDVj/1a/SnU2P/AFa/SnVkUFFFFABRRRQBXvpBFalmBIyOBWV9vi/55t/31Whq3/Hg31FcrqWoRaXp8l5cJM8ceMrBE0jnJxwqgk0jenFON2bX2+L/AJ5t/wB9Ufb4v+ebf99VwH/CzdB+2C08jVvtBj8zyf7Ln3bM43Y25xnjNdLpuoRapYR3duk0ccmcLPE0TjnHKsARQacsWbX2+L/nm3/fVH2+L/nm351QpOnWgOVGh9vhHSJvzo+3xf8APNv++q57Wtag0SK0kuI5HF1dxWqbMcM5wCc9q0qA5UX/ALfF/wA82/76o+3xf882/wC+qoUUByov/b4v+ebf99Ufb4v+ebf99VQooDlRo+bd3Ef/ABLfkIPzbiKTy9d/56L+lT6J9yX6itWmZufK7WRh+Xrv/PRf0o8vXf8Anov6VuUUC9r5Iw/L13/nov6UeXrv/PRf0rcooD2vkjD8vXf+ei/pR5eu/wDPRf0rcooD2vkjD8vXf+ei/pVHU01IRJ9tYMu75QPWuqpGRWILKCR0yOlA41rO9kYejxakuDIdsHpJyfwpG1CEOR5b8H+9W9XISf61vqa0grmNSfM7l/8AtGH/AJ5P/wB9Cj+0Yf8Ank//AH0K5TWvFmk6DcR299LK1xIpZYLeF5pNo6ttUEge9XtL1Wy1qwS902dZ4HyAy9iOoI6g+1aWRldm7/aMP/PJ/wDvoUf2jD/zyf8A76FZ1FPlQXNH+0Yf+eT/APfQo/tGH/nk/wD30KzqKOVBc0f7Rh/55P8A99Cj+0Yf+eT/APfQrOoo5UFzR/tGH/nk/wD30KllvolEeY35TI+asmp7n7sP/XMfzNLlQXLX9ow/88n/AO+hR/aMP/PJ/wDvoVg6tq9jolg15qc6wQqQMkEkk9AAOSfYVU0XxVpWvzSw2Esi3EIDPBPC0UgB6HawBx70cqC7Op/tGH/nk/8A30KP7Rh/55P/AN9Cs6inyoLmj/aMP/PJ/wDvoUf2jD/zyf8A76FZ1FHKguaP9ow/88n/AO+hR/aMP/PJ/wDvoVnUUcqC5o/2jD/zyf8A76FSrfRG2ZvLfAYDGayanT/jxk/3xScUO5a/tGH/AJ5P/wB9Cj+0Yf8Ank//AH0KzqyIPFGkXPiWXQbe7WXUIYjLJGgJCDIHLdM8jjrRyoV2dR/aMP8Azyf/AL6FH9ow/wDPJ/8AvoVnUU+VBc0f7Rh/55P/AN9Cj+0Yf+eT/wDfQrOoo5UFzR/tGH/nk/8A30KP7Rh/55P/AN9Cs6ijlQXNH+0Yf+eT/wDfQqW3vonmCiNwee/tWTU9n/x9L9D/ACpOKsFy1/aMP/PJ/wDvoUf2jD/zyf8A76FZ1YGreNdE0a+azu55WnjXdKsFu8vlL6uVB2j60cqC7Ow/tGH/AJ5P/wB9Cj+0Yf8Ank//AH0KyLS7t7+0iurOVZoJVDJIhyGHrU1HKguaP9ow/wDPJ/8AvoUf2jD/AM8n/wC+hWdRT5UFzR/tGH/nk/8A30KP7Rh/55P/AN9Cs6ijlQXNH+0Yf+eT/wDfQpf7Rh/55P8A99Cs2ijlQXOuiO6FCOhFPqO3/wCPaP8A3RUlcxoFFFFABRRRQBS1b/jwb6isCt/Vv+PBvqKwKR00vhOOf/ktsX/YAP8A6UVp6Prk+o+J9d02WNFi054ljZerb03HNNbRLk/EZNdyn2VdLNoRn5t/m7+npiqNxo+u6X4qv9U0BLS4h1JEE8dw5UxugIDDHUY7UFaobL4uu4/D/iS/8iMvpMzxxLzhwoB5/Ouf8Wah4wvfh5dalJ9hsLeWKNxErOZlBdf4hwDWrZ+ENXj8I+IdPvZ4ZrzU5nkSRThfmA/LpW3rugTav4Em0VJFjne3RFc8qGXBH4ZFAatGD4mGproGhf2y9vJP/blng24YLt3jHXv1q3rHjC4HiK40fSJdPgezRWuLi+kIUMwyFVRyTjnNTahpGta3oulx38Ntb3VpqUFxIschZTHG2SQfX2qHVPCt7b+JrnWdHtbC+F6iC4tr1ejKMBlbBxx1HtQGpf8ACfid9ce9tLtYBeWLhXa2ffHICMhlP9K6Ssbw7p95ZW0r6jDZQTSvkR2ce1UX0J7mtmgpbBRRRQM19E+5L9RWrWVon3JfqK1aZyVPiYUUUUEBRRRQAUUUUAFFFFABXISf61vqa6+uQk/1rfU1rTJkcZ4UUXHjnxZdzczJcQ26Z6rGIwQB7EsTS+EgLbxh4ps4eIFuI5VUdFZl+b+VSX+i61pviS51jwz9mmF9Gq3VtcsVG5eFcEd8cEVe8K6DPo8F3cajKs2o383nXLoPlB6BR7AVZJvUUUVQgooooAKKKKACp7n7sP8A1zH8zUFT3P3Yf+uY/maBnD+JlF18QPDFrPzApmnCnoXVQB/OjxEBbfEfwtcwgLLOLi3kI6smwMAfoRWl4o0K51X7Fe6XKkOo6fL5sDSfdbIwyn2Iqnpuiaxf+J4db8S/Zoms4mitLa3YsqlvvOSe5xipA6uiiiqEFFFFABRRRQAVOn/HjJ/vioKnT/jxk/3xQxldgGUg9CMGuDstIsdE+KthZ6ZAIYRpM7EA5LMZUJYk8kn1Nd7WBLoly/xAttaBT7NFYSW7DPzbmdSOPTikwN+iiimIKKKKACiiigAqez/4+l+h/lUFT2f/AB9L9D/Kh7DID0Ncb8O41n0vVruYBprrUp/NJHJAOAD+FdlXGNoniLQ7/UP+EZNnLaX8hm2XLFTbyHqRjqO+KTAk+HP7rSdRtE/1NrqM8UQ9F3ZArr6yPDGhDw9ocdmZfOmLNJNLj78jHLH8616a2AKKKKBBRRRQAUUUUAdbb/8AHtH/ALoqSo7f/j2j/wB0VJXKahRRRQAUUUUAVNSjaWzKoMnIrF+xXH/PP9RW/df6g/WqNI2hJpGd9iuP+ef6ij7Fcf8APP8AUVoZHqKKC+Zmf9iuP+ef6ij7Fcf88/1FaNNEiGQoHUuBkrnkCgOZlD7Fcf8APP8AUUfYrj/nn+orRooDmZnfYrj/AJ5/qKPsVx/zz/UVo0UBzMzvsVx/zz/UUfYrj/nn+orRooDmY/SIZIVk8xcZIxWjVWy6NVqmYSd2FFFFBIUUUUAFFFFABRRRQAVzD2NwZGIj7+orp6yT94/Wri7CZmfYLn/nn+oo+wXP/PP9RWlRWnMybGb9guf+ef6ij7Bc/wDPP9RWlRRzMLGb9guf+ef6ij7Bc/8APP8AUVpUUczCxm/YLn/nn+oo+wXP/PP9RWlRRzMLGb9guf8Ann+oqaeynZYsR9EAPI9TVynydE/3aXMwsZX2C5/55/qKPsFz/wA8/wBRWlRT5mFjN+wXP/PP9RR9guf+ef6itKijmYWM37Bc/wDPP9RR9guf+ef6itKijmYWM37Bc/8APP8AUUfYLn/nn+orSoo5mFjN+wXP/PP9RUy2U4s3XZyWBxkVcp4/1Lf7wpczCxlfYLn/AJ5/qKPsFz/zz/UVpUZp8zCxm/YLn/nn+oo+wXP/ADz/AFFaVFHMwsZv2C5/55/qKPsFz/zz/UVpUUczCxm/YLn/AJ5/qKPsFz/zz/UVpUUczCxm/YLn/nn+oqa1sp1uFLR4GD3HpVynw/60UuZhYyvsFz/zz/UUfYLn/nn+orSop8zCxm/YLn/nn+oo+wXP/PP9RWlRRzMLGb9guf8Ann+oo+wXP/PP9RWlRRzMLGb9guf+ef6ij7Bc/wDPP9RWlRRzMLGb9guf+ef6ij7Dc/8APP8AUVpUUczCxpwArboD1CipKbH/AKtfpTqwLCiiigAooooAhuv9QfrWVfErp9wQcERNgjtxWrdf6g/Wsm+5064x/wA8m/lSNI7Hk/gfSPCOpeCNKvNa1e4N/NAGnL6xMh3ZPYSDFd1ax6bZ+KbC1tdVugyae3lWRlZ43jBH7wk5yRkck1ifDbwrok/w30SW+0SykuGtgZHltlLE5PUkZqzcwCL4v2ISEiBNGlQBF4A3rgD8KBmrF488PTan9hjvt0hk8oOI28sv0278Yz+Nc9Nr2n6D8WtZl1Kfy/M0+2CIqlmc5foo5NZUWrw6G8Nv4V1Ca5DXmDot1akuu5/mIbHGOTk10enWiv8AGTV7qSD510y3VJCv3clsgH8qAOl0XXdO8Q2H2zSbhZ4g5RsAgow6qQeQfY1o1xvhGIw+OPGihCkbXsDqMYBJt0yR+NdlQMKKKKBhRRRQBasujVaqrZdGq1TMpbhRRRQSFFFFABRRRQAUUUUAFZJ+8frWtWSfvH61URM8/Fm3jfxvrdtqN3dx6Zo5jt4re1uHhDysu5nYqQTjIAFX/A15dxXutaBfXUt2dKuAsM0xy7ROMqCe5HTNZ8GpQeCvHevHWt8Fjqxjure52EpvVNjocdDwDV3wHFNfalrviGWF4YdTuF+zLIu1jGi4DY96oR2dFFFMAooooAKKKKACnydE/wB2mU+Ton+7SA4rxtdXd3rWieHLK6ltF1KR3uZYG2yCJBkhT2yTjNVIbVvBnj7SdPsbu7l0vWIpUMFzO03lTIAwZWYkjIzkZqz43SXTdf0LxIsLy29hI8V15a7ikbjG7HoCKqHUIfGfxE0afR902n6NHLNNc7CqtI67VQZ6nGSaAO/ooopgFFFFABRRRQAU8f6lv94Uynj/AFLf7wpAYHjXXJPDfgnVdWgAaa1t2aIN0L9F/UiuO1fw3eeGPB48SW2r6jLrdnGtzdSTXLtHcdC6GMnaF64wBjiuu8daLL4h8C6vpdrjz7i2YRZ7uOVH5gVyOu+MIfEvgb+w9PhmOuajGtrJZtEwaBjw5Y4wAOeaAPR7S4W7soLlPuzRrIPoRmpqgsbYWWnW9qDkQxLGD64GP6VPTAKKKKACiiigAp8P+sFMp8P+sFIBlebfEy31xXtb8ao1tp8N7bpFb2zFWlLONxkPce1ek1xvxPR5PC9qI1Zj/aNscAZ/jFAHYr90fSlpF+4PpS0wCiiigAooooAKKKKANWP/AFa/SnU2P/Vr9KdWRQUUUUAFFFFAEN1/qD9aodetW9QlMNoXUAnI61kf2jJ/zzj/ACpGsE2i2qqihUUKo6ADAFGxd+/aN2Mbsc1U/tGT/nnH+VH9oyf884/yoL5WWfJiEnmCJN/97aM/nTgihiwUbjwTjk1U/tGT/nnH+VH9oyf884/yoDlZbCKrEqoBbqQOtOql/aMn/POP8qP7Rk/55x/lQHKy7RVL+0ZP+ecf5Uf2jJ/zzj/KgfKy7RVL+0ZP+ecf5Uf2jJ/zzj/KgOVmvZdGq1Wfpdw06yFlUYI+6K0KZhLRhRRRQSFFFFABRRRQAUUUUAFZJ+8frWtXOPqUgkYeXHwfSrimxMtSRRyjEqK49GGacAAMAYA7CqP9pyf884/yo/tOT/nnH+VXysm5eoqj/acn/POP8qP7Tk/55x/lRysLl6iqP9pyf884/wAqP7Tk/wCecf5UcrC5eoqj/acn/POP8qP7Tk/55x/lRysLl6nydE/3azv7Tk/55x/lUs2oSKIsRx/MmenvRysLlkgMCGAIPUGmxxRxLiJFQeijFU/7Tk/55x/lR/acn/POP8qOVhcvUVR/tOT/AJ5x/lR/acn/ADzj/KjlYXL1FUf7Tk/55x/lR/acn/POP8qOVhcvUVR/tOT/AJ5x/lR/acn/ADzj/KjlYXL1PH+pb/eFZ39pyf8APOP8qmXUJDau/lx5DAdKOVhcsUwQxLIZFjQOerBRk/jVT+05P+ecf5Uf2nJ/zzj/ACo5WFy9RVH+05P+ecf5Uf2nJ/zzj/KjlYXL1FUf7Tk/55x/lR/acn/POP8AKjlYXL1FUf7Tk/55x/lR/acn/POP8qOVhcvU+H/WCs7+05P+ecf5VNbahI9wqmOMdeg9qOVhcsUjIrjDqGGc4IzVL+05P+ecf5Uf2nJ/zzj/ACo5WFy9RVH+05P+ecf5Uf2nJ/zzj/KjlYXL1FUf7Tk/55x/lR/acn/POP8AKjlYXL1FUf7Tk/55x/lR/acn/POP8qOVhcvUVR/tOT/nnH+VL/aUn/POP8qOVhc6KP8A1a/SnUyFt0CMe6g0+sSwooooAKKKKAKWrf8AHg31Fc+SFUljgAZJNdBq3/Hg31FcT4qiuZ/CGrRWOftL2cqxbeu7YcYpHTT+Ex4vF+p61JK3hLRRfWkTmP7bcz+TFIR12cEsPfGK1tC1fUNQeeDVtIm024gxklg8cgPdXHWofA1xZ3PgXR207aIVtI02j+EhQCD75zV7W9QtbDSbqW5vRaLHGS0owWT0OKC13NGq0d/azX01nHMjXECq0kYPKg9CfrXnEOsXOn65o8llda3NDe3IhmOoxARyAg8rwMGrejeH1HxT1pv7Svz5MVvLjzuHzk4PHI9qA5j0WiiigoKKKKACiiigDX0T7kv1FatZWifcl+orVpnJU+JhRRRQQFFFFABRRRQAUUUUAFchJ/rW+prr65CT/Wt9TWtMmRyvjLxpF4WtSILSS/vfLMogTgKg6szdhXQ2Nx9s0+3uSu3zolk25zjIzisL4gKv/CBay+0bvsjjOOcVraL/AMgGw/69o/8A0EVp1JL1FFFMQUUUUAFFFFABU9z92H/rmP5moKnufuw/9cx/M0DOf8R+IV0KC3WK2a7vbyXyra2Q4MjdeT2AHU1U0nxLeya6NG1/TV0+9khM0Bjm82OVQcHDYHIyOMVT8R4T4i+GHm/1RE6rnpv2jH6Zo8TEN8RPCSRcyq1yzAdk8sDn2zikB2FFFFMQUUUUAFFFFABU6f8AHjJ/vioKnT/jxk/3xQxlC/vYNN0+4vbxxHBbxtLIx7KBk1yK+ONTgs7fVtT0FrXRbllCz+eGljVjhXdMcDkdzjNXPiakknwz1wRAk/ZiSB/dBBb9M03xtLbN8L9QdSvkvZfusd8j5cfpSYHVgggEcg9KWqmkiRdGshNnzBAgfPrtGat0xBRRRQAUUUUAFT2f/H0v0P8AKoKns/8Aj6X6H+VD2GQVydx4s1O61K9g8N6MNQhsG2XE0lwIwXxkqgwdx/KusPQ4rjvhxhNH1KN+Jk1O483PXO7jP4UmB0Gg61b+INGh1C1DIsmQyP8AeRgcFT7g1o1x/wAOvm03VXj/ANQ+qXBiPYjd2/GuwprYAooooEFFFFABRRRQB1tv/wAe0f8AuipKjt/+PaP/AHRUlcpqFFFFABRRRQBS1b/jwb6iufrpb23a5tjGhAJPesz+xZ/76frSN6cklqcLN4GgivZrnQ9SvNHadi8sdqw8tmPU7TwD9KcngTTm029tr2e5vJr5QJrmaTMhxyMemDXcf2LP/fT9aP7Fn/vp+tBfNA4H/hBRNeWNxqOtX969jMJYBIQFUjjoBz9a0Ljwwj+JxrdpfXFpM6Kk8ceCs6qeAc/Wuu/sWf8Avp+tH9iz/wB9P1oDmgZ1FaP9iz/30/Wj+xZ/76frQPnj3M6itH+xZ/76frR/Ys/99P1oDnj3M6itH+xZ/wC+n60f2LP/AH0/WgOePcm0T7kv1FatU9Ps3tFcOwO49quUznm7y0CiiiggKKKKACiiigAooooAK5CT/Wt9TXX1hvok7OSJE5Oe9aQaW5MjnNZ0uLWtFutNndkjuYzGzL1ANWbS3W0s4bdCSsMaoCe4AxWx/YU//PSP9aP7Cn/56R/rWnNEmzMyitP+wp/+ekf60f2FP/z0j/WjmiFmZlFaf9hT/wDPSP8AWj+wp/8AnpH+tHNELMzKK0/7Cn/56R/rR/YU/wDz0j/WjmiFmZlT3P3Yf+uY/mauf2FP/wA9I/1qSXRppBHh0+Vdpo5kOzOV13QbXX7JYLovG8biSGaI4eJx0INU9G8KxaZqb6ld3tzqV80flLPckZROu1QOBXZf2FP/AM9I/wBaP7Cn/wCekf60c0RWZmUVp/2FP/z0j/Wj+wp/+ekf60c0QszMorT/ALCn/wCekf60f2FP/wA9I/1o5ohZmZRWn/YU/wDz0j/Wj+wp/wDnpH+tHNELMzKnT/jxk/3xVz+wp/8AnpH+tSro0wt2j3pksDRzIdmYc8EdzbyQToJIpFKOjDIYEYIrlYPh9axm3gn1K9udNtXDw2Ergxrg5UepA9DXoP8AYU//AD0j/Wj+wp/+ekf60c0RWZmdKK0/7Cn/AOekf60f2FP/AM9I/wBaOaIWZmUVp/2FP/z0j/Wj+wp/+ekf60c0QszMorT/ALCn/wCekf60f2FP/wA9I/1o5ohZmZU9n/x9L9D/ACq5/YU//PSP9akg0aaKYOzoQM9PpQ5Kw7MyK5nUPBcV1qFxd2GpXmmm7H+kpbMAsvbPPQ47iu5/sKf/AJ6R/rR/YU//AD0j/WjmiKzMDStLtdG0yGwsE2QQrhR3Puferlaf9hT/APPSP9aP7Cn/AOekf60c0QszMorT/sKf/npH+tH9hT/89I/1o5ohZmZRWn/YU/8Az0j/AFo/sKf/AJ6R/rRzRCzMyitP+wp/+ekf60f2FP8A89I/1o5ohZm1b/8AHtH/ALoqSmRIUhRT1UYp9c5oFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAf//Z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vd8mshivXpqT"
      },
      "outputs": [],
      "source": [
        "OneHotEncoder().fit_transform(X[[\"sexo\", \"ingreso\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUTQ9mqyXpqW"
      },
      "outputs": [],
      "source": [
        "OneHotEncoder().fit_transform(X).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmYXpwCfXpqZ"
      },
      "outputs": [],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QV09ESRDXpqd"
      },
      "outputs": [],
      "source": [
        "encoder = OneHotEncoder().fit(X)\n",
        "pd.DataFrame(encoder.transform(X).toarray(), columns=[c for cc in encoder.categories_ for c in cc])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnsH09A7Xpqg"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(encoder.transform(X).toarray(),\n",
        "            columns=[\n",
        "                f\"{column}_{category}\" for categories, column in zip(encoder.categories_, X.columns)\n",
        "                for category in categories\n",
        "            ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxsAi4OoXpql"
      },
      "source": [
        "### C.- Escalado y normalización\n",
        "\n",
        "En casi todos los algoritmos basados en algebra (regresiones y redes neuronales), los parámetros del modelo se encuentran con alguna variante de `gradient descent` y por tanto adolecen se sensibilidad a la escala de los parámetros. Por ello, tiende a ser útil llevar a todas las variables a un rango parejo. Esto normalmente se logra con el escalado de cada columna para que estén en el mismo rango o tengan media y desvíos igual.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbFRoxwsXpql"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler, Normalizer\n",
        "\n",
        "\n",
        "X = pd.DataFrame([\n",
        "    [1,-200,30000],\n",
        "    [2, 100, 50000],\n",
        "    [5,0, 100000]\n",
        "], columns=[f\"c{i}\" for i in range(3)])\n",
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03OivlTlKs-3"
      },
      "source": [
        "Con `StandardScaler` podemos transformar las variables a valores con media 0 y varianza 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfQXBjFLXpqr"
      },
      "outputs": [],
      "source": [
        "StandardScaler().fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YLejS2IXpqv"
      },
      "outputs": [],
      "source": [
        "StandardScaler().fit_transform(X).mean(axis=0).round(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-d06M6M4Xpqz"
      },
      "outputs": [],
      "source": [
        "StandardScaler().fit_transform(X).std(axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Re9hlVEMLPcl"
      },
      "source": [
        "También podemos escalarlos entre un valor mínimo y máximo, que por default es 0 y 1 usando `MinMaxScaler`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilODJqN9Xpq2"
      },
      "outputs": [],
      "source": [
        "MinMaxScaler().fit_transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgLCi5n0LqwE"
      },
      "source": [
        "Y con `MaxAbsScaler` podemos escalarlo por el máximo valor absoluto, es decir, haciendo 1 el valor máximo (en terminos absolutos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STf8gq4oXpq5"
      },
      "outputs": [],
      "source": [
        "MaxAbsScaler().fit_transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8nJ2IkUMD3x"
      },
      "source": [
        "La normalización es similar pero actua a nivel fila, y se usa cuadno vamos a usar algoritmos que miden distancias entre vectores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uH6Q8EH6Xpq8"
      },
      "outputs": [],
      "source": [
        "Normalizer().fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ePtJYrHXpq_"
      },
      "outputs": [],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnBYu4TQXprC"
      },
      "outputs": [],
      "source": [
        "Normalizer().fit_transform(StandardScaler().fit_transform(X))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llisoKdRXprH"
      },
      "outputs": [],
      "source": [
        "transformada = Normalizer().fit_transform(StandardScaler().fit_transform(X))\n",
        "np.square(transformada)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5EqfN6GXprK"
      },
      "outputs": [],
      "source": [
        "np.square(transformada).sum(axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3M4bzWCYXprN"
      },
      "source": [
        "### Creación de Variables (Feature Engineering)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4lQXN78XprN"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "X = pd.DataFrame([\n",
        "    [1,-20],\n",
        "    [2, 10],\n",
        "    [5,0]\n",
        "], columns=[f\"c{i+1}\" for i in range(2)])\n",
        "\n",
        "print(X)\n",
        "\n",
        "pd.DataFrame(PolynomialFeatures().fit_transform(X),\n",
        "             columns=[\"1\", \"c1\", \"c2\", \"c1^2\", \"c1*c2\", \"c2^2\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4ZxMwYaXprS"
      },
      "source": [
        "# Ejercitación\n",
        "\n",
        "### Leer los datos del titanic y transformarlos para lograr el mejor valor de la siguiente funcion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "F_Y4EZ4rXprT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.metrics import log_loss, accuracy_score, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHwrX2OrO_Rj"
      },
      "source": [
        "Creamos una función para calcular el resultado de un modelo simple de Regresión Logística"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "x7yVB6HLO-la"
      },
      "outputs": [],
      "source": [
        "def metric(X):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X.drop(\"Survived\", axis=1), X[\"Survived\"],\n",
        "                                                        test_size=0.25, random_state=42)\n",
        "    model = LogisticRegressionCV()\n",
        "    model.fit(X_train, y_train)\n",
        "    return log_loss(y_test,  model.predict_proba(X_test)), accuracy_score(y_test,  model.predict(X_test)), roc_auc_score(y_test,  model.predict(X_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThxPkA5yO1b2"
      },
      "source": [
        "Leemos los Datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "EkNjwcltXprV"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    data = pd.read_csv(\"../data/titanic.csv\", index_col=\"PassengerId\")\n",
        "except:\n",
        "    data = pd.read_csv(\"https://raw.githubusercontent.com/Argentan/DMA_LAB2/master/data/titanic.csv\", index_col=\"PassengerId\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dLxvmrLPUye"
      },
      "source": [
        "Esta es la métrica base, sin hacer nada más que permitir que el modelo corra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mgt7m8glO0_n"
      },
      "outputs": [],
      "source": [
        "metric(data.fillna(99999).drop(data.select_dtypes(\"O\"), axis=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOeLHS__SIGn"
      },
      "source": [
        "Vemos el resultado de estas métricas si predijeramos todos ceros (nadie sobrevive)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BeJ6e-lXprY"
      },
      "outputs": [],
      "source": [
        "accuracy_score(data[\"Survived\"],  np.zeros(data.shape[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2OXJVguQTID"
      },
      "outputs": [],
      "source": [
        "roc_auc_score(data[\"Survived\"],  np.zeros(data.shape[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjJwS17WSRzh"
      },
      "source": [
        "Vemos los Nulos en las Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KugG5BVRXprb"
      },
      "outputs": [],
      "source": [
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hEKox9uSU1Z"
      },
      "source": [
        "Vemos las variables de tipo Categóricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OzSVHyqXpre"
      },
      "outputs": [],
      "source": [
        "data.select_dtypes(\"O\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETkWXr2RSnsq"
      },
      "source": [
        "Otras características a estudiar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzxQnKPPXprh"
      },
      "outputs": [],
      "source": [
        "data.Cabin.fillna(\"NA\").value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zszQqwtxXprm"
      },
      "outputs": [],
      "source": [
        "data.Cabin.str[0].fillna(\"NA\").value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ft1IAP0CXpru"
      },
      "outputs": [],
      "source": [
        "data.Name.str.split(\",\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wRcs8l6Xpry"
      },
      "outputs": [],
      "source": [
        "data.Name.str.split(\",\").str[0].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRXxem4wS_kb"
      },
      "source": [
        "Consejos Adicionales para explorar:\n",
        "*    Analizar los valores vacios `\"\"`. Se puede asimilar a un Nulo?\n",
        "*    Analizar los valores cero `0`. Se puede asimilar a un Nulo?\n",
        "*    Se pueden agrupar pasajeros en grupos? Por ejemplo: Familia\n",
        "*    A partir de la edad, podemos crear una variable que mejore la separación del modelo?\n",
        "*    Se puede crear una variable \"Madre\"?\n",
        "*    Mejora el modelo si Normalizamos las variables continuas?\n",
        "*    Y si convertimos variables continuas en Rangos Fijos?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5gAZ6cdSsia"
      },
      "source": [
        "Realizar todos los pre-procesamientos posibles y ver cuanto se puede llegar a mejorar las métricas para un modelo simple"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "04_preprocesamiento_sklearn1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "orig_nbformat": 2,
    "vscode": {
      "interpreter": {
        "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
